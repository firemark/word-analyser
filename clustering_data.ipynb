{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from numpy import save as save_array\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from contextlib import contextmanager\n",
    "from time import time\n",
    "from sys import stdout\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def measure(title):\n",
    "    stdout.write('start %s... ' % title)\n",
    "    stdout.flush()\n",
    "    t0 = time()\n",
    "    yield\n",
    "    t1 = time()\n",
    "    seconds = t1 - t0\n",
    "    stdout.write('%02d:%06.3f\\n' % (seconds / 60.0, seconds % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#in_filename = 'output/parsed_logs_final'\n",
    "in_filename = 'output/parsed_logs_final_without_banned_ips'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with measure('vectorize content'):\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        binary=False,\n",
    "        max_features=5000,\n",
    "        ngram_range=(1, 1),\n",
    "        max_df=0.25,\n",
    "        min_df=2,\n",
    "    )\n",
    "    with open(in_filename) as f:\n",
    "        raw_x = vectorizer.fit_transform(f)\n",
    "print(\"n_samples: %d, n_features: %d\" % raw_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "SVD_DIMS = 20\n",
    "\n",
    "print\n",
    "print '## DIMS: %i ###' % SVD_DIMS\n",
    "with measure('dimension reduction'):\n",
    "    svd = TruncatedSVD(n_components=SVD_DIMS)\n",
    "    normalizer = Normalizer(copy=False)\n",
    "    lsa = make_pipeline(svd, normalizer)\n",
    "    x = lsa.fit_transform(raw_x)\n",
    "\n",
    "explained_variance = svd.explained_variance_ratio_.sum()\n",
    "\n",
    "print \"variance of the SVD step:\"\n",
    "for dim in range(SVD_DIMS):\n",
    "    print \"dimension {}: {:0.2f}%\".format(\n",
    "        dim, svd.explained_variance_ratio_[dim] * 100\n",
    "    )\n",
    "print \"Explained variance of the SVD step total: {:0.2f}%\".format(\n",
    "    explained_variance * 100\n",
    ")\n",
    "print(\"n_samples: %d, n_features: %d\" % x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "CLUSTERS = 20\n",
    "\n",
    "with measure('clustering'):\n",
    "    km = MiniBatchKMeans(n_clusters=CLUSTERS)\n",
    "    km.fit(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TERMS_PER_CLUSTER = 10\n",
    "\n",
    "centers = km.cluster_centers_\n",
    "clusters = len(centers)\n",
    "original_space_centroids = svd.inverse_transform(centers)\n",
    "order_centroids = original_space_centroids.argsort()[:, -TERMS_PER_CLUSTER:][:, ::-1]\n",
    "\n",
    "terms = vectorizer.get_feature_names()\n",
    "num_clusters = len(km.cluster_centers_)\n",
    "size = float(len(x))\n",
    "print 'total visitors:', size\n",
    "\n",
    "for i in range(clusters):\n",
    "    total_in_cluster = sum(km.labels_ == i)\n",
    "    print \"Cluster {:02d} (size: {:05.2f}%): {}\".format(\n",
    "        i + 1, total_in_cluster * 100.0 / size,\n",
    "        ', '.join(terms[ind] for ind in order_centroids[i])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "classifiers = {\n",
    "    'tree': DecisionTreeClassifier(),\n",
    "    'qda': QuadraticDiscriminantAnalysis(),\n",
    "    'forest': RandomForestClassifier(max_depth=5, n_estimators=20, max_features=10),\n",
    "    'svc_linear': LinearSVC(dual=False),\n",
    "}\n",
    "\n",
    "labels = km.labels_\n",
    "x_train, x_test, lab_train, lab_test = train_test_split(x, labels, test_size=0.2)\n",
    "\n",
    "for name, classifier in classifiers.items():\n",
    "    with measure('learning with class %s' % name):\n",
    "        classifier.fit(x_train, lab_train)\n",
    "    with measure('prediction with class %s' % name):\n",
    "        score = classifier.score(x_test, lab_test)\n",
    "    print 'score: %0.2f%%' % (score * 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "classifier = DecisionTreeClassifier()\n",
    "with measure('classifing'):\n",
    "    classifier.fit(x, labels)\n",
    "\n",
    "with measure('pipeling all and saving...'): \n",
    "    pipeline = make_pipeline(vectorizer, lsa, classifier)\n",
    "    with open('webapp/ml.pickle', 'w') as fp:\n",
    "        pickle.dump(pipeline, fp)\n",
    "        \n",
    "    with open('webapp/favorite-words', 'w') as fp:\n",
    "        for i in range(clusters):\n",
    "            words = ', '.join(terms[ind] for ind in order_centroids[i])\n",
    "            fp.write(words + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
